\section{Cheap Identification of backbone literals}
This section describes various ways that allow you to recognize backbone literals without an additional satisfiability check. Knowing these backbone literals early can speed up the individual calls to the SAT solver, because enforcing the backbone literals prevents the solver from trying to find solutions containing the negation of backbone literals, which by definition don't exist.

%Furthermore the latter two subsections here work solely on the set of already identified backbone literals.


\subsection{Axiomatic literals}
\label{subsec:axiomatic}
The most straightforward method to quickly identify backbone literals is to scan the formula for clauses with only a single literal. Since these clauses have only one possible way to become satisfied, that assignment must be used in every model of the formula and is therefore backbone.

Additionally you should check the CDCL table that your solver creates. If you look at this table you might find variable assignments through unit implication which happened before any decision. This includes all assignments from the paragraph above, but also those that are implied through these\footnote{Example: Formula $\{\{a\},\{\neg a, b\}\}$ has the backbone $\{a,b\}$, but only $a$ is immediately obvious.}.

It makes sense to do this check after every sat computation, as every different way that leads to a different model brings different learned clauses, that may sometimes consist of a single literal.

An expansion on this would be to look for pairs of clauses $(a,b)$, $(a,\neg b)$ for any two variables of the formula. The only way to fulfill this pair of clauses is to assign $a$ to $\top$\footnote{Which fits the resolution formula described in 
section \ref{ss:cdcl}}. This scheme can theoretically be applied to any clause size, but then you would require a quadratically increasing number of clauses to determine a backbone which would first increase computation time and secondly decrease the chance that the necessary set of clauses was available.

TODO was ist mit gelerntem auf basis von assumptions

\iffalse

However, if you want to use this feature in each iteration, make sure that your learned clauses do not stem from the means in which you enforce different models.

 for example the blocking clauses in $IBB$ or the checked literal in $BB$. Otherwise, you might confuse the backbone literals of your original problem $F$ with literals that only became axiomatic in your modified formula. \footnote{A simple example: You find an implicant $\{a\}$ with only a single literal. Then you add the blocking clause $\{\neg a\}$. But in $F \cup \{\neg a\}$ $\neg a$ is suddenly a backbone literal.}

The $BB$ solver manages this by having the feature of $assumptions$, which were first proposed in \cite{ENSO03}. These assumptions are assignments that are tested for whether the formula has a model that contains these assignments. For this, the CDCL table is first filled with decisions, that match the assumptions and subsequently the CDCL algorithm runs it's course ordinarily, except that the root decision level is after the entries that assign the assumptions. This has the effect that the assignments from the assumptions can not be taken back through backtracking, instead returning that $F$ is unsatisfiable under the given assumptions.

Once a model was found, all the learned clauses are checked whether they are related to the assumptions, and if so, they must be discarded, as is mentioned in \cite{WKS01}. This way, the assumptions will not have any long term effect
\footnote{\cite{ENSO03} actually states that ``all learned clauses are safe to keep''. \cite{WKS01} differs from \cite{ENSO03} in that here clauses are removed explicitely whereas assumptions are removed automatically.}.


Note that there are cases where you want to keep learned clauses between SAT calls. For example you can pass the solver the set of literals of which you already know that they are part of the backbone to help the solving process. Clauses that are learned from these learned literals in combination with other clauses of the formula will also help in this, so they should also be kept. In this case, for each identified backbone literal $l_b$ augment your formula $F$ to $F \cup \{l_b\}$, which is actually fully equivalent to $F$ in terms of the set of it's models, just more explicit in the fact that $l_b$ is a backbone of it.


Additionally, you can identify axiomatic literals if you check the table that is generated by CDCL when you search for a model for $F$. If it lists assignments that happened through unit propagation before any decision happened, then you can safely assume that they are axiomatic and part of the backbone, except of course if they were implied by modifications of F.

TODO tabelle mit wieviele literale dabei rausgefunden werden

%\begin{wraptable}{r}{10cm}
\fi
\subsection{Unit Implication}
\label{subsec:unitImpl}

yadayada

bedingung: damit c hier angewandt werden kann müssen alle literale darin backbone sein und $n_c - 1$ davon müssen bekannt sein.


We have tested this method in two solvers, $BB$ and a variant of $PrefBones$ that learns backbone literals only from clause learning as described in the previous subsection. This clearly showed that this method requires a critical mass of already known backbone literals to have a benefit, because as already stated, if there even exists a clause in $F$ where this method can be applied, you need to know the $n_c - 1$ other backbone literals in $c$ beforehand.

The learned backbone literals alone can rarely supply this, before the $PrefBones$ algorithm terminates from other conditions. However the iterative approach of the $BB$ solver, testing every yet unidentified literal individually, is much faster at providing positively identified backbone literals that you need to imply other backbone literals through unit implication.

\subsection{Implication through Cooccurrence}
\label{subsec:coocc}
Another method to recognize backbone literals from other ones is described in \cite{wbxcl16} and the rationale goes as follows:
%\newtheorem{Printed output}
\begin{lemma}
Given a backbone literal $a$ and another literal $b$. If $b$ occurs in all clauses that also contain $a$, then $\neg b$ must be part of the backbone. 

Proof: Assuming $\neg b$ was not in the backbone, then there would have to exist a model that contained $b$. Given that all clauses that contain $b$ also contain $a$, $a$ cannot be part of the backbone.
\end{lemma}

In other words, if we determine a new backbone literal, and all clauses that contain it also contain another literal, then we can add the negation of the latter to our backbone set. 

bisschen dazu schreibseln. Diskussion unit case ist ja auch selten

refinedEssentials benchmark hat selten überhaupt irgendwelche damit festgestellt, höchstens 4, bei zwischen 200 und 400 variablen
dimacs-hanoi5 hat 47

tabelle zum vergleich zwischen normalen KBB und KBB mit cooccurrence hinklatschen (je datei, nur implizierte backbone literale)

%\begin{wraptable}{r}{7cm}
\begin{wraptable}{L}{7cm} %[tbp]
\label{tab:coocBB} %for referencing
\begin{tabular}{l| c c c }
File& $n_{unit}$ & $n_{coocc}$\\
\hline
brock400-2.cnf & 0 & 0 \\
dimacs-hanoi5.cnf & 1465 & 47 \\
grieu-vmpc-s05-25.cnf & 565 & 0 \\
grieu-vmpc-s05-27.cnf & 142 & 0 \\
johnson8-2-4.cnf & 0 & 0 \\
fla-barthel-200-2.cnf & 33 & 0 \\
fla-barthel-200-3.cnf & 43 & 0 \\
fla-barthel-220-1.cnf & 149 & 0 \\
fla-barthel-220-2.cnf & 0 & 0 \\
fla-barthel-220-4.cnf & 0 & 0 \\
fla-barthel-240-2.cnf & 61 & 0 \\
\iffalse
fla-komb-200-3.cnf & 166 & 0 \\
fla-komb-200-5.cnf & 166 & 0 \\
fla-komb-220-1.cnf & 190 & 0 \\
fla-komb-220-3.cnf & 187 & 0 \\
fla-komb-220-4.cnf & 188 & 0 \\
fla-komb-220-5.cnf & 179 & 3 \\
fla-komb-240-2.cnf & 211 & 0 \\
fla-komb-240-3.cnf & 202 & 0 \\
fla-komb-240-5.cnf & 215 & 0 \\
fla-komb-260-1.cnf & 212 & 2 \\
fla-komb-260-3.cnf & 224 & 2 \\
fla-komb-260-4.cnf & 213 & 0 \\
fla-komb-280-1.cnf & 244 & 0 \\
fla-komb-280-3.cnf & 240 & 0 \\
fla-komb-280-4.cnf & 245 & 0 \\
fla-komb-280-5.cnf & 224 & 0 \\
fla-komb-300-3.cnf & 238 & 1 \\
fla-komb-300-4.cnf & 256 & 2 \\
fla-komb-300-5.cnf & 272 & 0 \\
fla-komb-320-2.cnf & 280 & 0 \\
fla-komb-320-3.cnf & 257 & 0 \\
fla-komb-320-5.cnf & 251 & 0 \\
fla-komb-340-1.cnf & 299 & 0 \\
fla-komb-340-2.cnf & 279 & 0 \\
fla-komb-340-3.cnf & 300 & 1 \\
fla-komb-340-4.cnf & 277 & 0 \\
fla-komb-340-5.cnf & 290 & 0 \\
fla-komb-360-1.cnf & 305 & 2 \\
fla-komb-360-4.cnf & 291 & 0 \\
fla-komb-360-5.cnf & 319 & 0 \\
fla-komb-380-2.cnf & 330 & 1 \\
fla-komb-380-3.cnf & 320 & 2 \\
fla-komb-380-4.cnf & 322 & 1 \\
fla-komb-380-5.cnf & 314 & 0 \\
fla-qhid-200-1.cnf & 185 & 0 \\
fla-qhid-200-2.cnf & 182 & 0 \\
fla-qhid-200-4.cnf & 181 & 0 \\
fla-qhid-200-5.cnf & 183 & 0 \\
fla-qhid-220-2.cnf & 190 & 0 \\
fla-qhid-220-3.cnf & 197 & 0 \\
fla-qhid-220-4.cnf & 197 & 0 \\
fla-qhid-220-5.cnf & 190 & 0 \\
fla-qhid-240-3.cnf & 10 & 0 \\
fla-qhid-240-5.cnf & 0 & 0 \\
fla-qhid-260-1.cnf & 6 & 0 \\
fla-qhid-260-2.cnf & 232 & 0 \\
fla-qhid-280-1.cnf & 1 & 0 \\
fla-qhid-280-3.cnf & 251 & 2 \\
fla-qhid-300-1.cnf & 260 & 0 \\
fla-qhid-300-4.cnf & 270 & 0 \\
fla-qhid-320-1.cnf & 296 & 0 \\
\fi
fla-qhid-320-2.cnf & 0 & 0 \\
fla-qhid-320-5.cnf & 283 & 2 \\
fla-qhid-340-2.cnf & 310 & 0 \\
fla-qhid-340-3.cnf & 309 & 3 \\
fla-qhid-340-4.cnf & 301 & 4 \\
fla-qhid-360-1.cnf & 326 & 0 \\
fla-qhid-360-5.cnf & 321 & 0 \\
fla-qhid-380-1.cnf & 344 & 2 \\
fla-qhid-400-3.cnf & 366 & 0 \\
fla-qhid-400-4.cnf & 359 & 0 \\
smallSatBomb.cnf & 0 & 0\\
\end{tabular}
\caption{Comparison of number of backbone literals identified through cooccurrence in comparison to the number identified through unit implication.}
%\end{wraptable}
\end{wraptable}


TODO überlegen, ob es sinnmacht überhaupt zwei variablen zu haben die in denselben klauseln auftauchen
