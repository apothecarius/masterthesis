\section{SAT Competition Benchmark}

For the first benchmark, I collected a set of 71 files from a SAT competition TODO welcher. The SAT competitions generally use problems that are difficult to solve compared to other problems of the same file size. This is in order to encourage development of solving strategies that reliably have good performance and not only for most of them. To save time during benchmarking, those files that took longer than around one minute for a single model computation were excluded, resulting in files that are generally around 30 kilobytes large. Additionally, problems where the duration for backbone computation averaged below one second were excluded, because here the small differences in the measurements could just as well be explained with external factors like the CPU throttling for a short time. To get meaningful testresults for such files, multiple testpasses should be conducted.

\begin{wraptable}{r}{7cm} %[tbp]
\begin{tabular}{l| c c c }
 & $t_{full}$ & $t_{sat}$ & $n_{sat}$ \\
 \hline
BB & 8.63 & 8.628 & 254 \\
IBB & 4.946 & 4.944 & 9 \\
KBB & 8.713 & 8.687 & 36 \\
PB0 & 31.78 & 31.779 & 4 \\
PB1 & 17.49 & 17.488 & 5 \\
PB1(amnes) & 10.867 & 10.865 & 6 \\
PB1(model) & 25.794 & 25.793 & 5 \\
PB1x & 5.064 & 5.062 & 9 \\
PB1a & 11.241 & 11.239 & 8 \\
PB1b & 9.785 & 9.783 & 6 \\
PB1c & 25.312 & 25.311 & 5 \\
PB1c(5\%) & 1064.097 & 1064.095 & 6 \\
PB1d & 26.746 & 26.745 & 5 \\
PB1e & 17.187 & 16.591 & 6 \\
PB1f & 15.971 & 15.97 & 6 \\
PB2 & 10.135 & 10.133 & 10 \\
PB2(5\%) & 5.232 & 5.229 & 9 \\
PB2(0.5\%) & 5.251 & 5.249 & 9 \\
PB3 & 20.927 & 20.922 & 4 \\
\end{tabular}
\caption{Averages of 64 testfiles taken from sat competitions. The columns indicate: The full time that the calculation took in seconds; The time that was spent in the sat solver; The number of sat calls (all three values are averages). }
\label{tab:satCompAvg} %for referencing
\end{wraptable}

The averaged time to compute the backbones of these 71 testfiles can be seen in \ref{tab:satCompAvg}. To prove that various computation strategies are implemented as good as possible\footnote{e.g. no noteworthy timeloss during setup of preferences}, the second column shows the time that was only spent in the sat solver.

Taking a look at this table, we can quickly see that for these instances, all solver that employed preferences as part of their algorithm performed much worse than those that did not\footnote{Which would be $BB$,$IBB$,$KBB$ and $PB1x$}.

IBB hatte bug, darum bessere leistung von pb1x vgl IBB\\
zweite tabelle zeigen, wenn blocking clause nicht entfernt wurde

\subsection{Importance of reusing learned clauses}
Table \ref{tab:learnedIbb} shows a comparison of individual benchmarks to highlight the importance of reusing learned clauses. While working with the $Sat4J$ library I noticed that the $IBB$ backbone algorithm was accidentally configured in a way that learned clauses would always be discarded between SAT computations. However, these learned clauses are still valid in later iterations of the $IBB$ algorithm. The only difference that the formula goes through during this algorithm, is that the blocking clause that ensures a new model repeatedly looses some of it's literals. As long as the set of solutions for a formula is only reduced, the learned clauses of that formula stay valid.\footnote{Example: With a formula without any clauses but three variablesyy $a$,$b$ and $c$ you can create eight models. With only the clause $\{a\}$ in your formula you can have four models, with only the clause $\{a \lor b\}$ you can have 6 models, with only the clause $\{a\lor b \lor c\}$ you can have 7 models.}

\begin{wraptable}{R}{8cm}
\begin{tabular}{l| c c }
File & $t_{keep}$ & $t_{discard}$ \\
\hline
brock400-2.cnf & 0.233 & 0.252 \\
dimacs-hanoi5.cnf & 1.41 & 1.596 \\
grieu-vmpc-s05-25.cnf & 71.945 & 78.964 \\
grieu-vmpc-s05-27.cnf & 554.52 & 648.697 \\
%johnson8-2-4.cnf & 0.001 & 0.001 \\
fla-barthel-200-2.cnf & 0.634 & 6.019 \\
fla-barthel-200-3.cnf & 0.619 & 2.16 \\
fla-barthel-220-1.cnf & 2.511 & 9.572 \\
fla-barthel-220-2.cnf & 7.497 & 17.759 \\
fla-barthel-220-4.cnf & 2.24 & 14.113 \\
fla-barthel-240-2.cnf & 3.632 & 50.552 \\
fla-komb-200-3.cnf & 0.236 & 0.301 \\
fla-komb-200-5.cnf & 0.114 & 0.276 \\
\iffalse
fla-komb-220-1.cnf & 0.293 & 0.475 \\
fla-komb-220-3.cnf & 0.229 & 0.466 \\
fla-komb-220-4.cnf & 0.129 & 0.217 \\
fla-komb-220-5.cnf & 0.167 & 0.247 \\
fla-komb-240-2.cnf & 0.326 & 0.413 \\
fla-komb-240-3.cnf & 0.395 & 0.392 \\
fla-komb-240-5.cnf & 0.478 & 0.481 \\
fla-komb-260-1.cnf & 1.518 & 3.032 \\
fla-komb-260-3.cnf & 1.964 & 3.093 \\
fla-komb-260-4.cnf & 1.452 & 1.469 \\
fla-komb-280-1.cnf & 3.625 & 4.384 \\
fla-komb-280-3.cnf & 0.926 & 2.375 \\
fla-komb-280-4.cnf & 1.438 & 1.442 \\
fla-komb-280-5.cnf & 2.678 & 4.124 \\
fla-komb-300-3.cnf & 3.46 & 8.989 \\
fla-komb-300-4.cnf & 2.72 & 5.816 \\
fla-komb-300-5.cnf & 2.095 & 2.092 \\
fla-komb-320-2.cnf & 2.649 & 4.34 \\
fla-komb-320-3.cnf & 10.821 & 10.135 \\
fla-komb-320-5.cnf & 8.367 & 15.784 \\
fla-komb-340-1.cnf & 4.453 & 7.647 \\
fla-komb-340-2.cnf & 10.553 & 18.844 \\
fla-komb-340-3.cnf & 9.665 & 9.619 \\
fla-komb-340-4.cnf & 19.507 & 30.767 \\
fla-komb-340-5.cnf & 11.085 & 16.571 \\
fla-komb-360-1.cnf & 9.639 & 11.066 \\
fla-komb-360-4.cnf & 13.362 & 22.839 \\
fla-komb-360-5.cnf & 19.295 & 35.347 \\
fla-komb-380-2.cnf & 41.745 & 89.802 \\
fla-komb-380-3.cnf & 43.062 & 59.364 \\
fla-komb-380-4.cnf & 105.37 & 179.518 \\
fla-komb-380-5.cnf & 57.441 & 107.179 \\
fla-qhid-200-1.cnf & 0.063 & 0.063 \\
fla-qhid-200-2.cnf & 0.127 & 0.122 \\
fla-qhid-200-4.cnf & 0.198 & 0.201 \\
fla-qhid-200-5.cnf & 0.162 & 0.163 \\
fla-qhid-220-2.cnf & 0.356 & 0.525 \\
fla-qhid-220-3.cnf & 0.231 & 0.355 \\
fla-qhid-220-4.cnf & 0.34 & 0.412 \\
fla-qhid-220-5.cnf & 0.399 & 0.504 \\
fla-qhid-240-3.cnf & 1.035 & 3.079 \\
fla-qhid-240-5.cnf & 0.624 & 0.724 \\
fla-qhid-260-1.cnf & 0.838 & 2.389 \\
fla-qhid-260-2.cnf & 0.602 & 0.613 \\
fla-qhid-280-1.cnf & 2.948 & 18.6 \\
fla-qhid-280-3.cnf & 1.592 & 2.516 \\
fla-qhid-300-1.cnf & 2.103 & 2.108 \\
fla-qhid-300-4.cnf & 3.385 & 3.741 \\
\fi
fla-qhid-320-1.cnf & 6.61 & 6.575 \\
fla-qhid-320-2.cnf & 9.227 & 101.17 \\
fla-qhid-320-5.cnf & 7.861 & 7.962 \\
fla-qhid-340-2.cnf & 11.922 & 13.688 \\
fla-qhid-340-3.cnf & 11.796 & 17.157 \\
fla-qhid-340-4.cnf & 9.454 & 9.297 \\
fla-qhid-360-1.cnf & 39.998 & 39.797 \\
fla-qhid-360-5.cnf & 10.698 & 10.849 \\
fla-qhid-380-1.cnf & 189.895 & 249.003 \\
fla-qhid-400-3.cnf & 83.098 & 130.834 \\
fla-qhid-400-4.cnf & 55.213 & 52.811 \\
smallSatBomb.cnf & 0.011 & 0.022 \\
\end{tabular}
\caption{Backbone computation time of the $IBB$ algorithm, once with keeping learned clauses ($t_{keep}$) and once discarding learned clauses between every sat call($t_{discard}$)}
\label{tab:learnedIbb} %for referencing
\end{wraptable}

The information contained in learned clauses is very valuable, as it prevents the solver from repeating invalid combinations of assignments that might even be likely to occur again. But if already learned clauses can guide the SAT solver away from possible conflicts, it could ideally return a model without any backtracking.


\subsection{Comparison of PB0 with PB1}
Table \ref{tab:satCompAvg} shows a strong performance difference between PB0 and PB1.

TODO grieu beispiel rauspicken (letzter sat call)

\begin{wraptable}{R}{7cm} %[tbp]
\begin{tabular}{l| c c c c}
& $t_{full}$ & $t_{sat}$ & $t_{last}$ & $n_{sat}$ \\
\hline			
PB0 & 1005.756 & 1005.753 & 810.946 & 3 \\
PB1 & 6741.638 & 6741.635 & 6594.098 & 2 \\
IBB & 556.815 & 556.719 & 361.825 & 2 \\
\end{tabular}
\caption{Comparison of runtime of file $grieu-vmpc-s05-27$ . $t_{last}$ shows the time that the very last sat call took.}
\label{tab:tLastGrieu} %for referencing
\end{wraptable}

stammt daher, dass zuletzt unsat errechnet wird. vonThore hat das problem nicht (selten überhaupt eine millisekunde gebraucht für letzten aufruf)

\subsection{Benefits of unit implication}
\label{ss:result_unit}
This section evaluates the effects of trying to recognize backbone literals through unit implication as described in section \ref{subsec:unitImpl}. Table \ref{tab:bbkbb} shows individual performance differences between the $BB$ solver supplied by Sat4J and my $KBB$ solver for comparison, as well as the backbone's size and the number of backbone literals identified through unit implication. The time columns also contain the number of sat calls that were comitted.\footnote{Most of the performance differences in table \ref{tab:bbkbb} can be explained with other reasons than actual algorithmic differences. $fla-barthel-220-4.cnf$ for example should not be faster with $KBB$ since here no backbone literal was determined through unit propagation. However I was able to reproduce this performance difference just through the order of what was called first, i.e. if the two solvers are called the other way around the timings are so as well. A possible explanation could be a power saving feature in modern processors.}

\begin{table} %[tbp]
\begin{tabular}{l| c c c c }
File & $t_{BB}(n_{sat})$ & $t_{KBB}(n_{sat})$ & $n_{unit}$ & $n_{backbone}$  \\
\hline
brock400-2.cnf & 0.041(254) & 0.038(254) & 0 & 0 \\
fla-komb-400-3.cnf & 1276.712(381) & 1241.124(45) & 336 & 379 \\
dimacs-hanoi5.cnf & 1.944(1931) & 1.836(281) & 1650 & 1931 \\
vonThore42.cnf & 0.018(398) & 0.014(51) & 345 & 346 \\
grieu-vmpc-s05-27.cnf & 261.091(678) & 281.083(536) & 142 & 677 \\
fla-komb-360-4.cnf & 14.937(337) & 14.936(45) & 292 & 333 \\
fla-qhid-360-1.cnf & 74.964(355) & 76.032(29) & 326 & 355 \\
grieu-vmpc-s05-25.cnf & 182.837(625) & 179.914(51) & 574 & 625 \\
fla-qhid-360-5.cnf & 20.678(350) & 20.892(29) & 321 & 349 \\
fla-barthel-220-4.cnf & 3.553(32) & 2.741(32) & 0 & 6 \\
9012345.cnf & 4.181(1483) & 6.734(813) & 670 & 1478 \\
fla-barthel-220-2.cnf & 8.183(23) & 8.109(23) & 0 & 4 \\
1098765.cnf & 1.208(938) & 1.291(493) & 444 & 921 \\
smallSatBomb.cnf & 0.013(26) & 0.012(19) & 7 & 9 \\
\end{tabular}
\caption{Benchmark results for a selection of files with a focus on the benefit of unit implication.
Rows indicate: The number of backbone literals identified through unit implication; the actual number of backbone literals; Calculationtime and number of sat calls of the solvers $KBB$ (using unit implication) and $BB$ (not doing unit implication, otherwise the same).}
%\end{wraptable}
\label{tab:bbkbb} %for referencing
\end{table}



The results drunter und drüber, auf einzeldateien eingehen

Begründungsvermutung: Hauptzeit geht für wenige schwierige Literale drauf, die nicht per unit implikation gefunden werden können. Könnte experimentell festgestellt werden, dur

%brock dateigröße: 500kb, fla dateigrößen ~30kb


reine sat zeit von kbb wurde auch gemessen: verlust durch suche liegt bei 0

%grieu-vmpc-s05-27 ist interessant beim vgl zwischen pb0 und pb1 (letzter satcall frisst tonnenweise zeit -> unsat bedingung kann teuer sein)



\subsection{Benefits of forgetting preferences}
schlechte ergebnisse von PB1c (0.05) vgl run2 mit run3 (run3 hat kein default vergessen)
